{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/VinamraOberoi/PSO-algorithm-for-DTIoV/blob/main/PSO_algorithm_v2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "vtzwdWXCpu1A"
      },
      "outputs": [],
      "source": [
        "import geopandas as gpd\n",
        "import random\n",
        "from shapely.geometry import Point\n",
        "import folium\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.neural_network import MLPRegressor\n",
        "from sklearn.model_selection import train_test_split\n",
        "from shapely.geometry import Polygon"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "0QTKzbMOp36x"
      },
      "outputs": [],
      "source": [
        "# Load the GeoJSON file for Delhi (replace 'delhi_boundary.geojson' with your actual GeoJSON file path)\n",
        "geojson_file = 'delhi_boundary.geojson'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "U8ys74Ump8sd"
      },
      "outputs": [],
      "source": [
        "# Load Delhi boundaries using GeoPandas\n",
        "delhi_gdf = gpd.read_file(geojson_file)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "t-ytefKkqDTg"
      },
      "outputs": [],
      "source": [
        "# Extract the polygon boundary of Delhi\n",
        "delhi_polygon = delhi_gdf['geometry'].values[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "FYYqna73qGAi"
      },
      "outputs": [],
      "source": [
        "# Function to generate random points within the Delhi polygon\n",
        "def generate_random_points_within_polygon(polygon, num_points):\n",
        "    points = []\n",
        "    minx, miny, maxx, maxy = polygon.bounds  # Bounding box of the polygon\n",
        "    while len(points) < num_points:\n",
        "        random_point = Point(random.uniform(minx, maxx), random.uniform(miny, maxy))\n",
        "        if polygon.contains(random_point):  # Ensure the point is within the polygon\n",
        "            points.append([random_point.y, random_point.x])  # Latitude, Longitude\n",
        "    return points"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "LAIZI0DAqppj"
      },
      "outputs": [],
      "source": [
        "# Generate the datasets\n",
        "num_vehicles = 1000\n",
        "num_rsus = 100\n",
        "num_mbs = 20\n",
        "\n",
        "delhi_streets_grid = {\n",
        "    # Generate 1000 Vehicle Locations within Delhi\n",
        "    \"Vehicle_Locations\": generate_random_points_within_polygon(delhi_polygon, num_vehicles),\n",
        "\n",
        "    # Generate 100 RSU Locations within Delhi\n",
        "    \"RSU_Locations\": generate_random_points_within_polygon(delhi_polygon, num_rsus),\n",
        "\n",
        "    # Generate 20 MBS Locations within Delhi\n",
        "    \"MBS_Locations\": generate_random_points_within_polygon(delhi_polygon, num_mbs),\n",
        "\n",
        "    # Cloud Location fixed in Connaught Place, Delhi\n",
        "    \"Cloud_Location\": [28.6139, 77.2090]  # Cloud server at Connaught Place, central Delhi\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "B0C7op2BqwQO"
      },
      "outputs": [],
      "source": [
        "# Particle Swarm Optimization (PSO) Parameters\n",
        "num_iterations = 1000  # Number of iterations for each swarm\n",
        "num_particles = 100  # Swarm size\n",
        "w = 0.5  # Inertia weight\n",
        "c1 = 1.5  # Cognitive parameter (particle's own best)\n",
        "c2 = 1.5  # Social parameter (swarm's global best)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "11-MHblKqy7Z"
      },
      "outputs": [],
      "source": [
        "# Task sizes and latencies (random values for simplicity)\n",
        "num_tasks = len(delhi_streets_grid['Vehicle_Locations'])\n",
        "task_sizes = np.random.uniform(0.5, 5, num_tasks)  # Task size in MB\n",
        "task_latencies = np.random.uniform(10, 100, num_tasks)  # Task latency in ms"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "OCdBTKsEq1VD"
      },
      "outputs": [],
      "source": [
        "# Calculate distance between two geographical points\n",
        "def calculate_distance(coord1, coord2):\n",
        "    return np.sqrt((coord1[0] - coord2[0]) ** 2 + (coord1[1] - coord2[1]) ** 2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "wAfyU0bQq3qz"
      },
      "outputs": [],
      "source": [
        "# Functions to compute latency based on allocation and vehicle distance from RSUs, MBS, and Cloud\n",
        "def compute_latency(position):\n",
        "    total_latency = 0\n",
        "    for i, allocation in enumerate(position):\n",
        "        vehicle_location = delhi_streets_grid[\"Vehicle_Locations\"][i]\n",
        "        if allocation == 0:  # Local processing\n",
        "            total_latency += 10  # Local processing latency\n",
        "        elif allocation == 1:  # RSU processing\n",
        "            rsu_location = random.choice(delhi_streets_grid[\"RSU_Locations\"])\n",
        "            distance = calculate_distance(vehicle_location, rsu_location)\n",
        "            total_latency += 30 + distance  # RSU latency + distance\n",
        "        elif allocation == 2:  # MBS processing\n",
        "            mbs_location = random.choice(delhi_streets_grid[\"MBS_Locations\"])\n",
        "            distance = calculate_distance(vehicle_location, mbs_location)\n",
        "            total_latency += 50 + distance  # MBS latency + distance\n",
        "        elif allocation == 3:  # Cloud processing\n",
        "            cloud_location = delhi_streets_grid[\"Cloud_Location\"]\n",
        "            distance = calculate_distance(vehicle_location, cloud_location)\n",
        "            total_latency += 100 + distance  # Cloud latency + distance\n",
        "    return total_latency"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "4YdeHb6Jq6LC"
      },
      "outputs": [],
      "source": [
        "# Function to compute system throughput based on task allocation\n",
        "def compute_throughput(position):\n",
        "    total_throughput = 0\n",
        "    for i, allocation in enumerate(position):\n",
        "        task_size = task_sizes[i]\n",
        "        if allocation == 0:  # Local processing\n",
        "            total_throughput += task_size / 10\n",
        "        elif allocation == 1:  # RSU processing\n",
        "            total_throughput += task_size / 30\n",
        "        elif allocation == 2:  # MBS processing\n",
        "            total_throughput += task_size / 50\n",
        "        elif allocation == 3:  # Cloud processing\n",
        "            total_throughput += task_size / 100\n",
        "    return total_throughput"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "yBYQlWA9q85w"
      },
      "outputs": [],
      "source": [
        "# Fitness function combining latency and throughput with weights w1 and w2 (w1 + w2 = 1)\n",
        "def fitness_function(position, w1=0.5, w2=0.5):\n",
        "    latency = compute_latency(position)\n",
        "    throughput = compute_throughput(position)\n",
        "    return w1 * latency + w2 * (1 / throughput)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "8oPBkcCBwjb9"
      },
      "outputs": [],
      "source": [
        "# Create Folium map centered in Delhi\n",
        "m = folium.Map(location=[28.6139, 77.2090], zoom_start=11)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "QmiJrT0cwnD1"
      },
      "outputs": [],
      "source": [
        "# Add RSU markers to the map\n",
        "for location in delhi_streets_grid[\"RSU_Locations\"]:\n",
        "    folium.Marker(location=location, popup=\"RSU\", icon=folium.Icon(color=\"green\")).add_to(m)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "CdQTdr-2wtac"
      },
      "outputs": [],
      "source": [
        "# Add MBS markers to the map\n",
        "for location in delhi_streets_grid[\"MBS_Locations\"]:\n",
        "    folium.Marker(location=location, popup=\"MBS\", icon=folium.Icon(color=\"orange\")).add_to(m)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4RNuwcv9ww21",
        "outputId": "49231e8f-a67a-4237-eace-d5834edbc511"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<folium.map.Marker at 0x266978afc70>"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Add Cloud marker\n",
        "folium.Marker(location=delhi_streets_grid[\"Cloud_Location\"], popup=\"Cloud\", icon=folium.Icon(color=\"red\")).add_to(m)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "keI7kgDKq_t-"
      },
      "outputs": [],
      "source": [
        "# Function to run PSO and visualize results (latency, throughput, fitness)\n",
        "def run_pso_and_report():\n",
        "    # Load previous best from file if it exists\n",
        "    try:\n",
        "        with open('pso_best.npy', 'rb') as f:\n",
        "            global_best_position = np.load(f)\n",
        "            global_best_fitness = np.load(f)\n",
        "    except FileNotFoundError:\n",
        "        global_best_position = None\n",
        "        global_best_fitness = np.inf\n",
        "\n",
        "    particles_position = np.random.randint(0, 4, size=(num_particles, num_tasks))\n",
        "    particles_velocity = np.random.uniform(-1, 1, (num_particles, num_tasks))\n",
        "\n",
        "    personal_best_position = np.copy(particles_position)\n",
        "    personal_best_fitness = np.inf * np.ones(num_particles)\n",
        "\n",
        "    if global_best_position is None:\n",
        "        global_best_position = np.copy(particles_position[0])\n",
        "        global_best_fitness = fitness_function(global_best_position)\n",
        "\n",
        "    for iteration in range(num_iterations):\n",
        "        for i in range(num_particles):\n",
        "            current_fitness = fitness_function(particles_position[i])\n",
        "\n",
        "            if current_fitness < personal_best_fitness[i]:\n",
        "                personal_best_fitness[i] = current_fitness\n",
        "                personal_best_position[i] = np.copy(particles_position[i])\n",
        "\n",
        "            if current_fitness < global_best_fitness:\n",
        "                global_best_fitness = current_fitness\n",
        "                global_best_position = np.copy(particles_position[i])\n",
        "\n",
        "        for i in range(num_particles):\n",
        "            r1 = np.random.rand(num_tasks)\n",
        "            r2 = np.random.rand(num_tasks)\n",
        "            particles_velocity[i] = (w * particles_velocity[i] +\n",
        "                                     c1 * r1 * (personal_best_position[i] - particles_position[i]) +\n",
        "                                     c2 * r2 * (global_best_position - particles_position[i]))\n",
        "\n",
        "            particles_position[i] = particles_position[i].astype(float) + particles_velocity[i]\n",
        "            particles_position[i] = np.clip(np.round(particles_position[i]), 0, 3).astype(int)\n",
        "\n",
        "    final_latency = compute_latency(global_best_position)\n",
        "    final_throughput = compute_throughput(global_best_position)\n",
        "    final_fitness = fitness_function(global_best_position, w1=0.7, w2=0.3)\n",
        "\n",
        "    print(f\"Final Latency: {final_latency}\")\n",
        "    print(f\"Final Throughput: {final_throughput}\")\n",
        "    print(f\"Final Fitness (w1=0.7, w2=0.3): {final_fitness}\")\n",
        "\n",
        "    m.save('delhi_pso_visualization.html')\n",
        "\n",
        "    # Save best to file\n",
        "    with open('pso_best.npy', 'wb') as f:\n",
        "        np.save(f, global_best_position)\n",
        "        np.save(f, global_best_fitness)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "bEHk31EtrIEN"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Final Latency: 10000\n",
            "Final Throughput: 271.6805063409095\n",
            "Final Fitness (w1=0.7, w2=0.3): 7000.001104238225\n"
          ]
        }
      ],
      "source": [
        "# Run the PSO simulation and report latency, throughput, and fitness\n",
        "run_pso_and_report()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "authorship_tag": "ABX9TyMlKxoggxkaBCPGSb1IVocr",
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
